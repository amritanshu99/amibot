{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4703d-9222-4575-bfac-9347f95ae6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\amrit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amrit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\amrit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading transformer model...\n",
      "âœ… Loaded CSV with encoding: Index(['Field', 'Value'], dtype='object')\n",
      "ðŸ’¾ Saved df.pkl, field_variants.pkl, and field_embeddings.pt to 'amibot_data/'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask AmiBot (type 'exit' to quit):  name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Matched: 'name'\n",
      "ðŸ“ Semantic: 0.44, ðŸ”¤ Fuzzy: 100.0\n",
      "ðŸ‘‰ Iâ€™m Amritanshu Mishra â€” this bot speaks from my data, my words, my world.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask AmiBot (type 'exit' to quit):  wife\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Matched: 'wife'\n",
      "ðŸ“ Semantic: 0.81, ðŸ”¤ Fuzzy: 100.0\n",
      "ðŸ‘‰ Committed for life â€” merged with Sneha Mishra in a lifelong partnership.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask AmiBot (type 'exit' to quit):  skills\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Matched: 'skills'\n",
      "ðŸ“ Semantic: 0.55, ðŸ”¤ Fuzzy: 100.0\n",
      "ðŸ‘‰ Skilled in MERN Stack, React, Node.js, and advanced AI/ML systems, including Transformers.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Install required packages (run once)\n",
    "!pip install -q sentence-transformers rapidfuzz nltk\n",
    "\n",
    "# ðŸ“¥ Imports\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rapidfuzz import fuzz\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ðŸ“Œ Download NLTK corpus\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# ðŸ§  Load transformer model\n",
    "print(\"ðŸ“¥ Loading transformer model...\")\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "# ðŸ“„ Load your CSV file (replace path if needed)\n",
    "csv_path = \"amibot.csv\"  # Ensure it has columns: 'Field', 'Value'\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='cp1252')  # fallback encoding\n",
    "\n",
    "print(\"âœ… Loaded CSV with encoding:\", df.columns)\n",
    "\n",
    "# ðŸ“š Preprocess data\n",
    "field_variants = []\n",
    "field_map = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    field_str = row[\"Field\"]\n",
    "    value = row[\"Value\"]\n",
    "    variants = [v.strip().lower() for v in field_str.split(\",\") if v.strip()]\n",
    "    for v in variants:\n",
    "        field_variants.append(v)\n",
    "        field_map[v] = value  # Map each variant to its value\n",
    "\n",
    "field_embeddings = model.encode(field_variants, convert_to_tensor=True)\n",
    "\n",
    "# ðŸ”§ Function: Correct typos (basic spell fix using regex for now)\n",
    "def correct_typos(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# ðŸ”§ Function: Expand with synonyms using WordNet\n",
    "def expand_with_synonyms(text):\n",
    "    words = text.split()\n",
    "    expanded_words = []\n",
    "    for word in words:\n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.add(lemma.name().replace(\"_\", \" \"))\n",
    "        if synonyms:\n",
    "            expanded_words.append(word + \" \" + \" \".join(list(synonyms)[:2]))\n",
    "        else:\n",
    "            expanded_words.append(word)\n",
    "    return \" \".join(expanded_words)\n",
    "\n",
    "# ðŸ¤– Function: Get AmiBot response\n",
    "def get_response(user_input, model, field_variants, field_embeddings, field_map, threshold=0.55, fuzz_threshold=55):\n",
    "    original_input = user_input.strip()\n",
    "    corrected_input = correct_typos(original_input)\n",
    "    expanded_input = expand_with_synonyms(corrected_input)\n",
    "\n",
    "    query_embedding = model.encode(expanded_input, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(query_embedding, field_embeddings)[0]\n",
    "\n",
    "    best_score = float(similarities.max())\n",
    "    best_idx = int(similarities.argmax())\n",
    "    best_field = field_variants[best_idx]\n",
    "    best_answer = field_map[best_field]\n",
    "\n",
    "    fuzzy_score = fuzz.token_set_ratio(original_input.lower(), best_field.lower())\n",
    "\n",
    "    if best_score >= threshold or fuzzy_score >= fuzz_threshold:\n",
    "        return f\"\\nâœ… Matched: '{best_field}'\\nðŸ“ Semantic: {best_score:.2f}, ðŸ”¤ Fuzzy: {fuzzy_score}\\nðŸ‘‰ {best_answer}\"\n",
    "    else:\n",
    "        return f\"\\nðŸ¤– Sorry, Iâ€™m not sure what you meant.\\nðŸ’¡ Did you mean: '{best_field}'?\\nPlease rephrase your question.\"\n",
    "\n",
    "# ðŸ’¾ Save necessary components for Flask app\n",
    "save_dir = \"amibot_data\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{save_dir}/df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "with open(f\"{save_dir}/field_variants.pkl\", \"wb\") as f:\n",
    "    pickle.dump(field_variants, f)\n",
    "\n",
    "with open(f\"{save_dir}/field_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(field_map, f)\n",
    "\n",
    "torch.save(field_embeddings, f\"{save_dir}/field_embeddings.pt\")\n",
    "\n",
    "print(\"ðŸ’¾ Saved df.pkl, field_variants.pkl, and field_embeddings.pt to 'amibot_data/'\")\n",
    "\n",
    "# ðŸ§ª Test in Notebook (example)\n",
    "while True:\n",
    "    user_input = input(\"\\nAsk AmiBot (type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = get_response(user_input, model, field_variants, field_embeddings, field_map)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c90978-973d-412f-a4c7-9dffc42cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install & Import Packages\n",
    "# !pip install -q sentence-transformers rapidfuzz nltk\n",
    "# Load the Transformer Model\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# This model converts text into dense vector embeddings.\n",
    "\n",
    "# Embeddings capture semantic meaning (not just exact words).\n",
    "\n",
    "# Itâ€™s fast and lightweight.\n",
    "# Internally:\n",
    "# \"father name\" â†’ [0.23, -0.14, ..., 0.01] (384-dim vector)\n",
    "# \"Whatâ€™s your dad's name?\" â†’ similar vector\n",
    "# 3. Read and Parse CSV\n",
    "# Each row in the CSV maps Field(s) â†’ Value (response).\n",
    "# 6. User Input Flow\n",
    "\n",
    "# Comma-separated synonyms like:\n",
    "# \"father name, dad name, papa\" are split and preprocessed.\n",
    "\n",
    "# Preprocess: Extract Field Variants\n",
    "# for row in df:\n",
    "#     variants = field_str.split(\",\")\n",
    "#     for v in variants:\n",
    "#         field_variants.append(v.lower().strip())\n",
    "#         field_map[v.lower()] = value\n",
    "# field_variants = [\"father name\", \"dad name\", \"papa\", \"your name\", ...]\n",
    "# field_map = {\n",
    "#   \"father name\": \"Anshul Sharma\",\n",
    "#   \"papa\": \"Anshul Sharma\",\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "# 5. Generate Embeddings\n",
    "# field_embeddings = model.encode(field_variants, convert_to_tensor=True)\n",
    "# Each field becomes a semantic vector:\n",
    "# \"father name\" â†’ tensor([0.12, -0.55, ..., 0.33])\n",
    "\n",
    "# 6. User Input Flow\n",
    "# def get_response(user_input, ...)\n",
    "# Internally:\n",
    "\n",
    "# a. Correct Typos\n",
    "# correct_typos(\"Dadâ€™s n@me!\") â†’ \"dads name\"\n",
    "# b. Expand with Synonyms\n",
    "# expand_with_synonyms(\"dads name\") â†’ \"dads name dad father\"\n",
    "\n",
    "# c. Encode Input\n",
    "# query_embedding = model.encode(expanded_input)\n",
    "# d. Computes similarity between query and each field:\n",
    "# \"What's your dadâ€™s name?\" vs [\"father name\", \"your name\", ...]\n",
    "# â†’ cosine scores like [0.87, 0.22, 0.04, ...]\n",
    "\n",
    "# e. Fuzzy Score\n",
    "# fuzz.token_set_ratio(\"whatâ€™s your dadâ€™s name\", \"father name\") â†’ 80\n",
    "\n",
    "# f. Threshold-Based Match\n",
    "# if similarity > 0.55 or fuzzy_score > 55:\n",
    "#     return correct response\n",
    "# else:\n",
    "#     return \"Sorry, Iâ€™m not sure...\"\n",
    "\n",
    "# 7. Save Artifacts for Flask\n",
    "\n",
    "# pickle.dump(df, field_variants, field_map)\n",
    "# torch.save(field_embeddings)\n",
    "# Avoid recomputing embeddings when deploying.\n",
    "\n",
    "# Use this in your Flask app without repeating preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2103bf3-dc98-461b-987b-52f1a8f5bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ðŸ”¢ Step | ðŸ§© Component             | ðŸ“ Description                         | ðŸ§  Internal Operation                                                      | ðŸ§ª Example                                            |\n",
    "# | ------- | ------------------------ | -------------------------------------- | -------------------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "# | 1ï¸âƒ£     | **Install Packages**     | Installs required libraries            | Downloads and sets up `sentence-transformers`, `rapidfuzz`, and `nltk`     | `pip install -q sentence-transformers rapidfuzz nltk` |\n",
    "# | 2ï¸âƒ£     | **Import Modules**       | Loads Python packages                  | Imports for NLP, embedding, fuzzy logic, and preprocessing                 | `import pandas as pd`, `import torch`, etc.           |\n",
    "# | 3ï¸âƒ£     | **Download WordNet**     | Enables synonym expansion              | Downloads NLTK corpora: `wordnet` & `omw-1.4`                              | `nltk.download('wordnet')`                            |\n",
    "# | 4ï¸âƒ£     | **Load CSV File**        | Loads personal Q\\&A data               | Reads `amibot.csv` into a DataFrame with 'Field' and 'Value' columns       | CSV sample: `father name, Anshul Sharma`              |\n",
    "# | 5ï¸âƒ£     | **Parse Field Variants** | Splits Field into multiple query forms | For each comma-separated variation in \"Field\", create mappings             | `\"father name, dad name\"` â†’ 2 keys                    |\n",
    "# | 6ï¸âƒ£     | **Build Mapping Dicts**  | Store phrases and answers              | `field_variants = []` stores queries, `field_map = {}` maps to values      | `\"dad name\" â†’ Anshul Sharma`                          |\n",
    "# | 7ï¸âƒ£     | **Generate Embeddings**  | Semantic vectors for field variants    | Converts all `field_variants` to dense vectors using `SentenceTransformer` | `\"father name\" â†’ [0.23, -0.54, ..., 0.11]`            |\n",
    "# | 8ï¸âƒ£     | **Typo Correction**      | Pre-clean user input                   | Removes symbols and lowercases the input via regex                         | `\"Dadâ€™s name?\" â†’ \"dads name\"`                         |\n",
    "# | 9ï¸âƒ£     | **Synonym Expansion**    | Enhances semantic reach                | Adds 1â€“2 synonyms from WordNet to each word                                | `\"dad\"` â†’ `\"dad father papa\"`                         |\n",
    "# | ðŸ”Ÿ      | **User Input Encoding**  | Transforms input to embedding          | Uses model to encode expanded user input                                   | `\"Who is your dad?\" â†’ tensor`                         |\n",
    "# | 1ï¸âƒ£1ï¸âƒ£  | **Cosine Similarity**    | Semantic comparison                    | Measures angle between input vector and all stored field vectors           | `cos_sim = 0.82 with \"father name\"`                   |\n",
    "# | 1ï¸âƒ£2ï¸âƒ£  | **Fuzzy Matching**       | Textual string similarity              | Uses `fuzz.token_set_ratio` to score rough matches                         | `\"Who is your dad?\" vs \"father name\" â†’ 76`            |\n",
    "# | 1ï¸âƒ£3ï¸âƒ£  | **Response Selection**   | Final decision on best match           | Chooses highest score above thresholds: `cos_sim > 0.55 or fuzzy > 55`     | âœ… Match: `\"father name\" â†’ Anshul Sharma\"`             |\n",
    "# | 1ï¸âƒ£4ï¸âƒ£  | **Fallback Message**     | Handles low-match inputs               | Suggests closest match or asks user to rephrase                            | `\"ðŸ¤– Sorry, Iâ€™m not sure...\"`                         |\n",
    "# | 1ï¸âƒ£5ï¸âƒ£  | **Save Artifacts**       | Save all required objects              | Dumps model outputs and mappings to `amibot_data/` folder for Flask        | `field_embeddings.pt`, `field_map.pkl`                |\n",
    "# | 1ï¸âƒ£6ï¸âƒ£  | **Interactive Testing**  | Run in Jupyter loop                    | Continuously prompt for input, display match & answer                      | `input(\"Ask AmiBot: \")`                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc92fe00-dc24-41b9-9026-571c010b595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ðŸ”Ž User Input             | ðŸŽ¯ Cleaned Input        | ðŸ§  Expanded Input                   | ðŸ”— Best Match    | ðŸ“ Cosine Sim | ðŸ”¤ Fuzzy Score | âœ… Final Response            |\n",
    "# | ------------------------- | ----------------------- | ----------------------------------- | ---------------- | ------------- | -------------- | --------------------------- |\n",
    "# | \"Whatâ€™s your dadâ€™s name?\" | `whats your dads name`  | `whats your dads name dad father`   | `father name`    | 0.87          | 78             | `Anshul Sharma`             |\n",
    "# | \"Tell me your birthday\"   | `tell me your birthday` | `tell me your birthday natal birth` | `dob`            | 0.74          | 68             | `09 September 1996`         |\n",
    "# | \"Favourite dish?\"         | `favourite dish`        | `favourite dish food meal`          | `favourite food` | 0.51          | 43             | `ðŸ¤– Sorry, please rephrase` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c125251-3dae-40b9-8518-1417c558ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ðŸ“ File               | ðŸ“„ Format      | ðŸ§  Contents                           |\n",
    "# | --------------------- | -------------- | ------------------------------------- |\n",
    "# | `df.pkl`              | Pickle         | Original CSV DataFrame                |\n",
    "# | `field_variants.pkl`  | Pickle         | All phrases extracted from 'Field'    |\n",
    "# | `field_map.pkl`       | Pickle         | Maps each variant â†’ Value             |\n",
    "# | `field_embeddings.pt` | PyTorch Tensor | Vector representation of all variants |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3862d4-22a9-4726-af6c-d1834c70dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Setting               | Description                                 | Recommendation                    |\n",
    "# | --------------------- | ------------------------------------------- | --------------------------------- |\n",
    "# | `threshold = 0.55`    | Minimum cosine similarity to consider match | Lower to 0.5 for broader matches  |\n",
    "# | `fuzz_threshold = 55` | Minimum fuzzy ratio for textual match       | Keep above 50 to avoid false hits |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683f0bf5-aca5-41a2-8ace-0c6a5206b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚           START AMIBOT SYSTEM              â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”„ Load CSV File (amibot.csv)              â”‚\n",
    "# â”‚ - Columns: 'Field', 'Value'                â”‚\n",
    "# â”‚ - Example: \"father name, dad name\", \"Anshul Sharma\" â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”„ Parse and Preprocess Fields              â”‚\n",
    "# â”‚ - Split comma-separated fields             â”‚\n",
    "# â”‚ - Store in:                                â”‚\n",
    "# â”‚     â€¢ field_variants (list of queries)     â”‚\n",
    "# â”‚     â€¢ field_map (dict: query â†’ answer)     â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ âš™ï¸ Encode All field_variants Using Model    â”‚\n",
    "# â”‚ - SentenceTransformer(\"all-MiniLM-L6-v2\")  â”‚\n",
    "# â”‚ - Convert each query to semantic vector    â”‚\n",
    "# â”‚ - Save as: field_embeddings (tensor list)  â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ’¾ Save Artifacts to Disk                   â”‚\n",
    "# â”‚ - df.pkl, field_map.pkl, field_variants.pklâ”‚\n",
    "# â”‚ - field_embeddings.pt                      â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â–¶ï¸ SYSTEM IS READY â€” USER ENTERS A QUERY BELOW:\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ§ USER INPUTS QUESTION (e.g., â€œDadâ€™s name?â€) â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”§ Step 1: Preprocess Input                  â”‚\n",
    "# â”‚ - Lowercase                                 â”‚\n",
    "# â”‚ - Remove punctuation and extra whitespace   â”‚\n",
    "# â”‚ â†’ \"Dadâ€™s name?\" â†’ \"dads name\"               â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”§ Step 2: Synonym Expansion (WordNet)      â”‚\n",
    "# â”‚ - For each word in input:                  â”‚\n",
    "# â”‚     â€¢ Add top 1â€“2 synonyms                 â”‚\n",
    "# â”‚ â†’ \"dads name\" â†’ \"dads name father dad\"     â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”§ Step 3: Encode Expanded Input            â”‚\n",
    "# â”‚ - Use same SentenceTransformer model       â”‚\n",
    "# â”‚ - Generate semantic embedding              â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ” Step 4: Semantic Comparison              â”‚\n",
    "# â”‚ - Cosine similarity between user input &   â”‚\n",
    "# â”‚   each field_variant embedding             â”‚\n",
    "# â”‚ â†’ Get best_match, best_score               â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”¤ Step 5: Fuzzy String Matching            â”‚\n",
    "# â”‚ - Compare original input vs. best_match    â”‚\n",
    "# â”‚ - Use RapidFuzz `token_set_ratio()`        â”‚\n",
    "# â”‚ â†’ Get fuzzy_score                          â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ”Ž Step 6: Check Match Thresholds           â”‚\n",
    "# â”‚ - If best_score â‰¥ 0.55  OR                 â”‚\n",
    "# â”‚   fuzzy_score â‰¥ 55                         â”‚\n",
    "# â”‚   â†’ Proceed with best_match                â”‚\n",
    "# â”‚ - Else â†’ Go to fallback response           â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ âœ… MATCH FOUND      â”‚    â”‚ âŒ NO CONFIDENT MATCH       â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ” Step 7: Retrieve Answer from field_map   â”‚\n",
    "# â”‚ - Lookup value using best_match            â”‚\n",
    "# â”‚ - Example: \"father name\" â†’ \"Anshul Sharma\" â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#       â”‚                            â”‚\n",
    "#       â–¼                            â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ’¬ Return Response:         â”‚   â”‚ ðŸ’¬ Fallback:                           â”‚\n",
    "# â”‚   âœ… Matched: â€˜father nameâ€™ â”‚   â”‚   ðŸ¤– Sorry, Iâ€™m not sure what you meantâ”‚\n",
    "# â”‚   ðŸ‘‰ Anshul Sharma          â”‚   â”‚   ðŸ’¡ Suggested closest: â€˜father nameâ€™ â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "#                   â”‚\n",
    "#                   â–¼\n",
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ ðŸ” Loop: Wait for Next User Query or Exit   â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb062ab9-4159-422d-91cd-4ffbc4df5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | ðŸ”¢ Index | ðŸ§¾ File               | ðŸ“¦ Format         | ðŸ“Œ Contents                                                                     | ðŸ§  Purpose                                                                                | ðŸ“‚ Example                                                                                  |\n",
    "# | -------- | --------------------- | ----------------- | ------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n",
    "# | 1ï¸âƒ£      | `df.pkl`              | Pickled DataFrame | A full table mapping each **field** (e.g., `Name`) to its **response**          | Used to show all available knowledge, help with UI listing, manual lookup, or export      | `{\"field\": \"Name\", \"value\": \"Amritanshu Mishra\"}`                                           |\n",
    "# | 2ï¸âƒ£      | `field_map.pkl`       | Pickled dict      | Dictionary mapping every **user variant** to a **canonical field**              | Enables the bot to map fuzzy or alternative inputs to a consistent, known response source | `{\"your name\": \"Name\", \"who are you\": \"Name\"}` maps both to the `\"Name\"` field              |\n",
    "# | 3ï¸âƒ£      | `field_variants.pkl`  | Pickled list      | A list of **all accepted phrases** or variants asked by users                   | Used as the raw text input to create sentence embeddings or apply fuzzy matching          | `[\"your name\", \"what's your full name\", \"who are you\", \"tell me your name\"]`                |\n",
    "# | 4ï¸âƒ£      | `field_embeddings.pt` | PyTorch tensor    | A tensor with **vectorized embeddings** (e.g., SentenceTransformer) of variants | Allows fast **cosine similarity search** when user input doesnâ€™t exactly match a variant  | Embedding for \"what's your full name\" stored as a 384-dim vector to match to `\"Name\"` field |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ce2a7b-8cfe-45d3-aaa1-6f231177df0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model.save('./local_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf13cc9-ee24-47a5-8286-66bd2c98adbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparaphrase-MiniLM-L3-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./local_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\backend.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Literal\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_datasets_caching, is_datasets_available\n\u001b[0;32m     13\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\util.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download, snapshot_download\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m coo_matrix\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:2611\u001b[0m\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[0;32m   2610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m-> 2611\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[0;32m   2613\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[0;32m   2614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_meta_registrations.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _add_op_to_registry,\n\u001b[0;32m     14\u001b[0m     _convert_out_params,\n\u001b[0;32m     15\u001b[0m     global_decomposition_table,\n\u001b[0;32m     16\u001b[0m     meta_table,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_decomp\\__init__.py:276\u001b[0m\n\u001b[0;32m    272\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcore_aten_decompositions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomDecompTable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_decomp\\decompositions.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_meta_registrations\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_prims\\__init__.py:525\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# Elementwise unary operations\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28mabs\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_make_elementwise_unary_prim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimpl_aten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_promotion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPLEX_TO_FLOAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m acos \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macos\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macos,\n\u001b[0;32m    535\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    536\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    537\u001b[0m )\n\u001b[0;32m    539\u001b[0m acosh \u001b[38;5;241m=\u001b[39m _make_elementwise_unary_prim(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macosh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    541\u001b[0m     impl_aten\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39macosh,\n\u001b[0;32m    542\u001b[0m     doc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    543\u001b[0m     type_promotion\u001b[38;5;241m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[38;5;241m.\u001b[39mDEFAULT,\n\u001b[0;32m    544\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_prims\\__init__.py:493\u001b[0m, in \u001b[0;36m_make_elementwise_unary_prim\u001b[1;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_elementwise_unary_prim\u001b[39m(\n\u001b[0;32m    487\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, type_promotion: ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    488\u001b[0m ):\n\u001b[0;32m    489\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03m    Creates an elementwise unary prim.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_prim(\n\u001b[0;32m    494\u001b[0m         schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(Tensor self) -> Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    495\u001b[0m         meta\u001b[38;5;241m=\u001b[39mpartial(_prim_elementwise_meta, type_promotion\u001b[38;5;241m=\u001b[39mtype_promotion),\n\u001b[0;32m    496\u001b[0m         return_type\u001b[38;5;241m=\u001b[39mRETURN_TYPE\u001b[38;5;241m.\u001b[39mNEW,\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    498\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_prims\\__init__.py:321\u001b[0m, in \u001b[0;36m_make_prim\u001b[1;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     mutates_args \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    317\u001b[0m         arg\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m cpp_schema\u001b[38;5;241m.\u001b[39marguments\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arg\u001b[38;5;241m.\u001b[39malias_info\u001b[38;5;241m.\u001b[39mis_write\n\u001b[0;32m    320\u001b[0m     ]\n\u001b[1;32m--> 321\u001b[0m     prim_def \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprims::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prim_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmutates_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     prim_def\u001b[38;5;241m.\u001b[39mregister_fake(meta)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# all view ops get conj/neg fallthroughs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_library\\custom_ops.py:173\u001b[0m, in \u001b[0;36mcustom_op\u001b[1;34m(name, fn, mutates_args, device_types, schema)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_library\\custom_ops.py:154\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    151\u001b[0m     schema_str \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m    153\u001b[0m namespace, opname \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 154\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mCustomOpDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Check that schema's alias annotations match those of `mutates_args`.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_library\\custom_ops.py:204\u001b[0m, in \u001b[0;36mCustomOpDef.__init__\u001b[1;34m(self, namespace, name, schema, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autocast_cpu_dtype: Optional[_dtype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m get_library_allowing_overwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_to_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disabled_kernel: \u001b[38;5;28mset\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    206\u001b[0m OPDEFS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qualname] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_library\\custom_ops.py:624\u001b[0m, in \u001b[0;36mCustomOpDef._register_to_dispatcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was no fake impl registered for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is necessary for torch.compile/export/fx tracing to work. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.register_fake` to add an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    620\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake impl.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    621\u001b[0m         )\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_abstract_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 624\u001b[0m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m autograd_impl \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mmake_autograd_impl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opoverload, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    627\u001b[0m lib\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, autograd_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m, with_keyset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\library.py:193\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[1;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[0;32m    190\u001b[0m     _library\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mwarn_deploy()\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m frame \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe(_stacklevel)\n\u001b[0;32m    195\u001b[0m caller_module \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(frame)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_library\\utils.py:54\u001b[0m, in \u001b[0;36mget_source\u001b[1;34m(stacklevel)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_source\u001b[39m(stacklevel: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a string that represents the caller.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    Example: \"/path/to/foo.py:42\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    etc.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mlineno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m source\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:1624\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1622\u001b[0m start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1626\u001b[0m     lines \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:952\u001b[0m, in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (file\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    950\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource code not available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 952\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module:\n\u001b[0;32m    954\u001b[0m     lines \u001b[38;5;241m=\u001b[39m linecache\u001b[38;5;241m.\u001b[39mgetlines(file, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:878\u001b[0m, in \u001b[0;36mgetmodule\u001b[1;34m(object, _filename)\u001b[0m\n\u001b[0;32m    875\u001b[0m         f \u001b[38;5;241m=\u001b[39m getabsfile(module)\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[0;32m    877\u001b[0m         modulesbyfile[f] \u001b[38;5;241m=\u001b[39m modulesbyfile[\n\u001b[1;32m--> 878\u001b[0m             \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m modulesbyfile:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(modulesbyfile[file])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ntpath.py:689\u001b[0m, in \u001b[0;36mrealpath\u001b[1;34m(path, strict)\u001b[0m\n\u001b[0;32m    687\u001b[0m     path \u001b[38;5;241m=\u001b[39m join(cwd, path)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 689\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43m_getfinalpathname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m     initial_winerror \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "model.save('./local_model')\n",
    "\n",
    "# Loading model locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4618844-f7a1-4935-9337-537be6665460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
